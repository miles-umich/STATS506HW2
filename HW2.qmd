---
title: "HW2"
author: "Margaret Miles"
format: html
editor: visual
---

## STATS 506 - HW2

Margaret Miles

## **Problem 1 - Modified Random Walk**

Consider a 1-dimensional random walk with the following rules:

Start at 0. At each step, move +1 or -1 with 50/50 probability. If +1 is chosen, 5% of the time move +10 instead. If -1 is chosen, 20% of the time move -3 instead. Repeat steps 2-4 times. (Note that if the +10 is chosen, it’s not +1 then +10, it is just +10.)

Write a function to determine the end position of this random walk.

The input and output should be:

Input: The number of steps

Output: The final position of the walk

random_walk(10) \[1\] 4

random_walk(10) \[1\] -11

We’re going to implement this in different ways and compare them.

**a. Implement the random walk in these three versions:**

Version 1: using a loop.

```{r}

#' Version 1 of random walk
#'
#' Takes a random step number count based on input starting at 0, and returns a random output
#' 
#' @params n = number of steps in the walk
#' @returns final = final position of the walk
#' 
#' @examples
#' ver1(10) = 4
#' ver1(10) = -11
#' 
ver1 <- function(n){
  # start at 0
  walk <- 0
  steps <- 1
  # At each step from 1 to n input  
  for (steps in 1:n){
    # move +1 or -1 with 50/50 probability
    move <- sample(c(1,-1), size = 1, prob = c(0.5, 0.5))
    # take a step in that direction
    # print(move)
    walk <- walk + move
    # +1 is chosen, 5% of the time move +10 instead (9 because you already stepped 1)
    if (move > 0) {
      walk <- walk + sample(c(0, 9), 1, prob = c(0.95, 0.05))
      # print(walk)
    } else {
      # If -1 is chosen, 20% of the time move -3 instead. (-2 because you already stepped -1)
      walk <- walk + sample(c(0, -2), 1, prob = c(0.80, 0.20))
      # print(walk)
    }
  }
  final <- walk
  return(final)
}

ver1(10)
ver1(10)
```

Version 2: using built-in R vectorized functions. (Using no loops.) (Hint: Does the order of steps matter?)

```{r}
#' Version 2 of random walk
#'
#' Takes a random step number count based on input starting at 0, and returns a random output
#' using vectorized functions
#' 
#' @params n = number of steps in the walk
#' @returns final = final position of the walk
#' 
#' @examples
#' ver1(10) = 4
#' ver1(10) = -11
#' 
ver2 <- function(n){
  # set up moves +1 or -1
  steps <- sample(c(1, -1), n, replace = TRUE)
  # print(steps)
  
  # +10 jump 5% of the time when base is +1
  steps[steps == 1] <- 1 + rbinom(sum(steps == 1), 1, 0.05) * 9
  # print(steps)
  
  # -3 jump 20% of the time
  steps[steps == -1] <- -1 +rbinom(sum(steps == -1), 1, 0.20) * -2
  # print(steps)
  
  # then sum to find final spot
  final <- sum(steps)
  return(final)
}

ver2(10)
ver2(10)
```

Version 3: Implement the random walk using one of the “apply” functions.

```{r}
#' Version 3 of random walk
#'
#' Takes a random step number count based on input starting at 0, and returns a random output
#' using apply functions
#' 
#' @params n = number of steps in the walk
#' @returns final = final position of the walk
#' 
#' @examples
#' ver1(10) = 4
#' ver1(10) = -11
#' 
ver3 <- function(n){
  # set up moves +1 or -1
  steps <- sample(c(1, -1), n, replace = TRUE)
  
  # using apply function, +10 jump 5% of the time when base is +1
  # and -3 jump 20% of the time when base is -1
  walk <- vapply(steps, function(x){
    if(x == 1){
      x <- sample(c(1, 10), 1, prob = c(0.95, 0.05))
    } else {
      x <- sample(c(-1, -3), 1, prob = c(0.80, 0.20))
    }
  }, numeric(1))
  # print(walk)
  return(sum(walk))
}

ver3(10)
ver3(10)
```

Demonstrate that all versions work by running the following: random_walk1(10) random_walk2(10) random_walk3(10) random_walk1(1000) random_walk2(1000) random_walk3(1000)

```{r}
random_walk1 <- ver1
random_walk2 <- ver2
random_walk3 <- ver3

random_walk1(10) 
random_walk2(10) 
random_walk3(10) 
random_walk1(1000) 
random_walk2(1000) 
random_walk3(1000)

```

**b. Demonstrate that the three versions can give the same result. Show this for both n=10 and n=1000. (You will need to add a way to control the randomization.)**

```{r}

# version #1 walk for same result
random_walk1_same <- function(n) {
  
  # set up with +1 or -1
  steps <- sample(c(1, -1), n, replace = TRUE)
  
  # check to see if start is the same
  # print(steps)
  
  # At each step from 0 to n input  
  for (i in 1:n){
    # +1 is chosen, 5% of the time move +10 
    if (steps[i] > 0) {
      steps[i] <- ifelse(runif(1) < 0.05, 10, 1)
    } else {
      # If -1 is chosen, 20% of the time move -3 
      steps[i] <- ifelse(runif(1) < 0.20, -3, -1)
    }
  }
  
  # print(steps)
  # sum
  final <- sum(steps)
  return(final)
}

# version #2 walk for same result
random_walk2_same <- function(n) {
  
  # set up with +1 or -1
  steps <- sample(c(1, -1), n, replace = TRUE)
  
  # check to see if start is the same
  # print(steps)
  
  # uniform random draws
  u <- runif(n)

  # step 1: replace the +1’s
  steps[steps == 1]  <- ifelse(u[steps == 1] < 0.05, 10, 1)
  
  # step 2: replace the -1’s
  steps[steps == -1] <- ifelse(u[steps == -1] < 0.20, -3, -1)
 
  # print(steps)
  # then sum to find final spot
  final <- sum(steps)
  return(final)
}

# version #3 walk for same result
random_walk3_same <- function(n) {
  
  # set up with +1 or -1
  steps <- sample(c(1, -1), n, replace = TRUE)
  
  # check to see if start is the same
  # print(steps)
  
  # using apply function, +10 jump 5% of the time when base is +1
  # and -3 jump 20% of the time when base is -1
  walk <- vapply(steps, function(x){
    if(x == 1){
      ifelse(runif(1) < 0.05, 10, 1)
    } else {
      ifelse(runif(1) < 0.20, -3, -1)
    }
  }, numeric(1))
  
  # print(walk)
  return(sum(walk))
}

set.seed(67)
random_walk1_same(10)
set.seed(67)
random_walk2_same(10)
set.seed(67)
random_walk3_same(10)


set.seed(67)
random_walk1_same(1000)
set.seed(67)
random_walk2_same(1000)
set.seed(67)
random_walk3_same(1000)

```

**c. Use the microbenchmark package to clearly demonstrate the speed of the implementations. Compare performance with a low input (1,000) and a large input (100,000). Discuss the results.**

```{r}
library(microbenchmark)

# Benchmark with n = 1,000
set.seed(67)
microbenchmark(
  walk1 = random_walk1_same(1000),
  walk2 = random_walk2_same(1000),
  walk3 = random_walk3_same(1000)
)

# Benchmark with n = 100,000
set.seed(67)
microbenchmark(
  walk1 = random_walk1_same(100000),
  walk2 = random_walk2_same(100000),
  walk3 = random_walk3_same(100000)
)


```

The results show that even in small implementation, vectorization was significantly faster. There is not much of a difference between a loop and apply, however loop is faster actually. This shows up even stronger when you run it for 10,000 times. Its extremely much faster to vectorize. My apply is longer because it calls two functions instead of 1 for the loop.

**d. What is the probability that the random walk ends at 0 if the number of steps is 10? 100? 1000? Defend your answers with evidence based upon a Monte Carlo simulation.**

```{r}
#' Monte Carlo Simulation 
#'
#' 
#' 
#' @params n = number of steps
#' @params trials = number of trials 
#' @params seed = seed for randomness
#' @returns results with all the information of the runs
#' 
#' @examples
#' ver1(10) = 4
#' ver1(10) = -11
#' 
mc_sim_prob <- function(n, trials, seed){
  set.seed(seed)
  
  # set up vectors for storage
  sums <- vector("list", 3)
  hits <- numeric(3)
  
  # run each random walk over # of trials
  sums[[1]] <- replicate(trials, random_walk1_same(n))  # N draws random walk 1(n)
  sums[[2]] <- replicate(trials, random_walk2_same(n))  # N draws random walk 2(n)
  sums[[3]] <- replicate(trials, random_walk3_same(n))  # N draws random walk 3(n)
  
  # store how many times it ends at 0
  hits[1] <- sum(sums[[1]] == 0)
  hits[2] <- sum(sums[[2]] == 0)
  hits[3] <- sum(sums[[3]] == 0)
  
  # results in a data frame
  results <- data.frame(
    n = n,
    trials = trials,
    
    walk1_hits   = hits[1],
    walk1_p_hat  = hits[1] / trials,
    walk1_ci_low = binom.test(hits[1], trials)$conf.int[1],
    walk1_ci_up  = binom.test(hits[1], trials)$conf.int[2],
    
    walk2_hits   = hits[2],
    walk2_p_hat  = hits[2] / trials,
    walk2_ci_low = binom.test(hits[2], trials)$conf.int[1],
    walk2_ci_up  = binom.test(hits[2], trials)$conf.int[2],
    
    walk3_hits   = hits[3],
    walk3_p_hat  = hits[3] / trials,
    walk3_ci_low = binom.test(hits[3], trials)$conf.int[1],
    walk3_ci_up  = binom.test(hits[3], trials)$conf.int[2]
  )
  return(results)
}

# random walk ends at 0 if the number of steps is 10? 100? 1000?
mc1 = mc_sim_prob(10, 10000, 67)
mc2 = mc_sim_prob(100, 10000, 67)
mc3 = mc_sim_prob(1000, 10000, 67)

cat("Number of steps:", mc1$n, "\n",
    "Number of MC sims:", mc1$trials, "\n",
    "Probability of 0 steps for Walk 1:", mc1$walk1_p_hat*100, 
    "% Lower Bound:", mc1$walk1_ci_low, 
    " Upper Bound:", mc1$walk1_ci_up, "\n",
    "Probability of 0 steps for Walk 2:", mc1$walk2_p_hat*100, 
    "% Lower Bound:", mc1$walk2_ci_low, 
    " Upper Bound:", mc1$walk2_ci_up, "\n",
    "Probability of 0 steps for Walk 3:", mc1$walk3_p_hat*100, 
    "% Lower Bound:", mc1$walk3_ci_low, 
    " Upper Bound:", mc1$walk3_ci_up, "\n", "\n")

cat("Number of steps:", mc2$n, "\n",
    "Number of MC sims:", mc2$trials, "\n",
    "Probability of 0 steps for Walk 1:", mc2$walk1_p_hat*100, 
    "% Lower Bound:", mc2$walk1_ci_low, 
    " Upper Bound:", mc2$walk1_ci_up, "\n",
    "Probability of 0 steps for Walk 2:", mc2$walk2_p_hat*100, 
    "% Lower Bound:", mc2$walk2_ci_low, 
    " Upper Bound:", mc2$walk2_ci_up, "\n",
    "Probability of 0 steps for Walk 3:", mc2$walk3_p_hat*100, 
    "% Lower Bound:", mc2$walk3_ci_low, 
    " Upper Bound:", mc2$walk3_ci_up, "\n", "\n")

cat("Number of steps:", mc3$n, "\n",
    "Number of MC sims:", mc3$trials, "\n",
    "Probability of 0 steps for Walk 1:", mc3$walk1_p_hat*100, 
    "% Lower Bound:", mc3$walk1_ci_low, 
    " Upper Bound:", mc3$walk1_ci_up, "\n",
    "Probability of 0 steps for Walk 2:", mc3$walk2_p_hat*100, 
    "% Lower Bound:", mc3$walk2_ci_low, 
    " Upper Bound:", mc3$walk2_ci_up, "\n",
    "Probability of 0 steps for Walk 3:", mc3$walk3_p_hat*100, 
    "% Lower Bound:", mc3$walk3_ci_low, 
    " Upper Bound:", mc3$walk3_ci_up, "\n", "\n")
```

## **Problem 2 - Mean of Mixture of Distributions**

The number of cars passing an intersection is a classic example of a Poisson distribution. At a particular intersection, Poisson is an appropriate distribution most of the time, but during rush hours (hours of 8am and 5pm) the distribution is really normally distributed with a much higher mean.

**Using a Monte Carlo simulation, estimate the average number of cars that pass an intersection under the following assumptions:**

- From midnight until 7 AM, the distribution of cars per hour is Poisson with mean 1.
- From 9am to 4pm, the distribution of cars per hour is Poisson with mean 8. 
- From 6pm to 11pm, the distribution of cars per hour is Poisson with mean 12. 
- During rush hours (8am and 5pm), the distribution of cars per hour is Normal with mean 60 and variance 12 Accomplish this without using any loops.

(Hint: This can be done with extremely minimal code.)

```{r}
# trails
n = 10000

# From midnight until 7:59 AM, the distribution of cars per hour is Poisson with mean 1.
time1 <- mean(rpois(n, 1))

# From 9am to 4pm, the distribution of cars per hour is Poisson with mean 8. 
time2 <- mean(rpois(n, 8))

# From 6pm to 11:59pm, the distribution of cars per hour is Poisson with mean 12. 
time3 <- mean(rpois(n, 12))

# During rush hours (8am and 5pm), the distribution of cars per hour is 
# Normal with mean 60 and variance 12 
time4 <- mean(rnorm(n, mean = 60, sd = 12))

#sum over all hours the average for a day
cars <- time1*8 + time2*7 + time3*6 + time4*2
print(cars)
```

## **Problem 3 - Linear Regression**

Use the following code to download the YouTube Superbowl commercials data:
```{r}
youtube <- read.csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-02/youtube.csv')
```

Information about this data can be found at https://github.com/rfordatascience/tidytuesday/tree/main/data/2021/2021-03-02. The research question for this project is to decide which of several attributes, if any, is associated with increased YouTube engagement metrics.

**a. Often in data analysis, we need to de-identify it. This is more important for studies of people, but let’s carry it out here. Remove any column that might uniquely identify a commercial. This includes but isn’t limited to things like brand, any URLs, the YouTube channel, or when it was published. Report the dimensions of the data after removing these columns.**

```{r}
# remove all idenfying columns
youtube_deID <- youtube[, !(names(youtube) %in% 
   c("brand", "superbowl_ads_dot_com_url", "youtube_url", 
     "title", "description", "thumbnail", "channel_title"))]

dim(youtube_deID)
```

**b. For each of the following variables, examine their distribution.**

Determine whether i) The variable could be used as is as the outcome in a linear regression model, ii) The variable can use a transformation prior to being used as the outcome in a linear regression model, or iii) The variable would not be appropriate to use as the outcome in a linear regression model.

For each variable, report which category it falls in. If it requires a transformation, carry such a transformation out and use that transformation going forward.

- View counts
- Like counts
- Dislike counts
- Favorite counts
- Comment counts
(Hint: At least the majority of these variables are appropriate to use.)

```{r}
# examine distribution of view count
hist(youtube_deID$view_count)
hist(log10(youtube_deID$view_count), breaks = 50, main="Log10 view counts")
# view count has some very large numbers, meaning that if I do a log transformation I can see it more clearly and show that it has a relatively normal distribution. It might have some outliers but nothing crazy so I'm going to log transform it for the dataset
youtube_deID$view_count <- log10(youtube_deID$view_count)
# remove view counts that are NA
youtube_deID <- subset(youtube_deID, !is.na(view_count))


#examine distribution of like count
hist(youtube_deID$like_count)
hist(log10(youtube_deID$like_count), breaks = 50, main="Log10 view counts")
hist(sqrt(youtube_deID$like_count), breaks = 50, main="sqrt view counts")
# like count has a lot of zeros, so it might be helpful to separate those out into their own column
youtube_deID$zero_likes <- youtube_deID$like_count == 0
youtube_deID$like_count[youtube_deID$like_count == 0] <- NA
# try to also do it with 1 or 0
youtube_deID$zero_likes <- youtube_deID$like_count < 3
youtube_deID$like_count[youtube_deID$like_count < 3] <- NA

# this looks reasonably normal with these edits, so I would just log transform it
youtube_deID$like_count <- log10(youtube_deID$like_count)
hist(youtube_deID$like_count)

# examine distribution of dislike count
hist(youtube_deID$dislike_count)
hist(log10(youtube_deID$dislike_count + 1), breaks = 50, main="Log10 dislike counts")

# lots of zeros again, and a few 1s so remove them 
youtube_deID$zero_dislikes <- youtube_deID$dislike_count < 1
youtube_deID$dislike_count[youtube_deID$like_count < 1] <- NA
# remove counts that are NA
youtube_deID <- subset(youtube_deID, !is.na(dislike_count))
hist(log10(youtube_deID$dislike_count), breaks = 50, main="Log10 dislike counts")
# this looks good now to use for a linear regression

# examine distribution of fav count
hist(youtube_deID$favorite_count)
# favorite is almost all zero, meaning that we should not use it at all for the linear regression

# examine distribution of comment count
hist(youtube_deID$comment_count)
hist(log10(youtube_deID$comment_count + 1), breaks = 50, main="Log10 comment counts")

# lots of zeros again, and a few 1s so remove them 
youtube_deID$zero_comments <- youtube_deID$comment_count < 1
youtube_deID$comment_count[youtube_deID$comment_count < 1] <- NA
# remove counts that are NA
youtube_deID <- subset(youtube_deID, !is.na(comment_count))
hist(log10(youtube_deID$comment_count), breaks = 50, main="Log10 comment counts")
# this looks good now to use for a linear regression


```

**c. For each variable in part b. that are appropriate, fit a linear regression model predicting them based upon each of the seven binary flags for characteristics of the ads, such as whether it is funny. Control for year as a continuous covariate.**

Discuss the results. Identify the direction of any statistically significant results.

```{r}


```

**d. Consider only the outcome of view counts. Calculate manually (without using lm) by first creating a proper design matrix, then using matrix algebra to estimate. Confirm that you get the same result as lm did in part c.**

```{r}


```
